{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_tools import file_utils as filu\n",
    "from python_tools import module_utils as modu\n",
    "from python_tools import inspect_utils as iu\n",
    "from python_tools import package_utils as pku\n",
    "from python_tools import pathlib_utils as plu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete process of cleaning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Purpose: Take an unordered module file and to clean it up\n",
    "so avoids circular imports that could result in errors. And\n",
    "also make it look professional\n",
    "\n",
    "\n",
    "---- old ----\n",
    "1) Get all of the modules used\n",
    "2) Divide the modules into those referenced by outside packages and those not\n",
    "3) Get all of the member variables\n",
    "4) Get all of the doc strings\n",
    "5) Arrange in the following order:\n",
    "--------------\n",
    "\n",
    "\n",
    "1) Run the replacement to put the right qualifiers in front of a module \n",
    "using the right package\n",
    "2) Get all the docstrings and replace in the file with nothing\n",
    "3) Find all of the module at the beginning of the line\n",
    "4) Determine the package that each module came from (if it did have one)\n",
    "5) Determine the parent module (if any)\n",
    "6) Put the correct prefix in front of module if not already have it\n",
    "- and add the relative one to those inside current package\n",
    "\n",
    "--------------------------------------------\n",
    "7) Why can't go collect current variables?\n",
    "- because there could be lists  that screw up the regex\n",
    "* the variables may sometimes depend on another class (but handle those on case by case)\n",
    "--------------------------------------------\n",
    "\n",
    "8) Replace the docstrng and the modules (at the begginning of line) with empty strings\n",
    "9) write the data in following order\n",
    "- at beginning: non-referencing modules, doc strings\n",
    "- at end: referencing modules\n",
    "\n",
    "non-referencing modules\n",
    "#local veraibles\n",
    "doc strings\n",
    "rest of code\n",
    "referencing modules\n",
    "itself\n",
    "\n",
    "-- things going to think about: \n",
    "those not at the start of the line --> do not want using the dot operator\n",
    "for relative (other than that everything else should be the same)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_tools import file_utils as filu\n",
    "filu.search_directory_files_for_str(\n",
    "    \"/python_tools/python_tools/\",\n",
    "    search_str=\"tqdm_utils import tqdm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/python_tools/python_tools/networkx_utils.py\"\n",
    "verbose = True\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Copy and paste document into new file if not overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_path = /python_tools/python_tools/networkx_utils_replaced.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from python_tools import system_utils as su\n",
    "\n",
    "\n",
    "filepath= Path(filepath)\n",
    "curr_mod = Path(filepath).stem\n",
    "\n",
    "if not overwrite:\n",
    "    output_path = filepath.parents[0] / Path(f\"{filepath.stem}_replaced{filepath.suffix}\")\n",
    "    su.copy_file(filepath,output_path)\n",
    "else:\n",
    "    output_path = filepath\n",
    "\n",
    "if verbose:\n",
    "    print(f\"output_path = {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Run replacement to put right qualifiers in front of something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filtering_utils',\n",
       " 'json_utils',\n",
       " 'matplotlib_utils',\n",
       " 'statistics_visualizations',\n",
       " 'requirement_utils',\n",
       " 'networkx_utils',\n",
       " 'pretty_print_confusion_matrix',\n",
       " 'numpy_utils',\n",
       " 'ipyvolume_movie_utils',\n",
       " 'dict_utils',\n",
       " 'regex_utils',\n",
       " 'hash_utils',\n",
       " 'inspect_utils',\n",
       " 'statistics_utils',\n",
       " 'general_utils',\n",
       " 'string_utils',\n",
       " 'algorithms_utils',\n",
       " 'ipyvolume_utils',\n",
       " 'pandas_utils',\n",
       " 'pathlib_utils',\n",
       " 'system_utils',\n",
       " 'package_utils',\n",
       " 'scipy_utils',\n",
       " 'seaborn_utils',\n",
       " 'matlab_utils',\n",
       " 'argparse_utils',\n",
       " 'module_utils',\n",
       " 'function_utils',\n",
       " 'networkx_utils_replaced',\n",
       " 'file_utils',\n",
       " 'data_struct_utils',\n",
       " 'linalg_utils',\n",
       " 'widget_utils',\n",
       " 'dj_utils',\n",
       " 'example_re',\n",
       " 'tqdm_utils',\n",
       " 'mesh_utils']"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packages = [\n",
    "    \"/python_tools/python_tools/\",\n",
    "    \"/machine_learning_tools/machine_learning_tools/\",\n",
    "    \"/pytorch_tools/pytorch_tools/\",\n",
    "    \"/graph_tools/graph_tools/\",\n",
    "    \"/meshAfterParty/meshAfterParty/\",\n",
    "    \"/neuron_morphology_tools/neuron_morphology_tools/\",\n",
    "]\n",
    "\n",
    "pkg_to_module = {k.split(\"/\")[1]:pku.module_names_from_directories(k)\n",
    "                for k in packages}\n",
    "\n",
    "directory = packages[0]\n",
    "package_name = directory.split(\"/\")[1]\n",
    "modules = pku.module_names_from_directories(directory)\n",
    "\n",
    "modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- easy initial replacement --\n",
      "# of substitutions = 27\n",
      "  --> output_filepath = /python_tools/python_tools/networkx_utils_replaced.py\n",
      "-- harder initial replacement --\n",
      "# of substitutions = 1\n",
      "  --> output_filepath = /python_tools/python_tools/networkx_utils_replaced.py\n",
      "-- easier relative replacement --\n",
      "# of substitutions = 7\n",
      "  --> output_filepath = /python_tools/python_tools/networkx_utils_replaced.py\n",
      "-- harder relative replacement --\n",
      "# of substitutions = 1\n",
      "  --> output_filepath = /python_tools/python_tools/networkx_utils_replaced.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/python_tools/python_tools/networkx_utils_replaced.py')"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_tools import regex_utils as ru\n",
    "from python_tools import file_utils as filu\n",
    "\n",
    "word_comb = ru.word_pattern\n",
    "#modules = [\"general_utils\",\"numpy_utils\"]\n",
    "modules_or = f\"(?:{'|'.join(modules)})\"\n",
    "\n",
    "# easy_import_pattern = (\n",
    "# f\"(?:(import {modules_or} as {word_comb}))\"\n",
    "# f\"|(?:from {word_comb} (import {modules_or} as {word_comb}))\"\n",
    "# f\"|(?:(import {modules_or}))\"\n",
    "# f\"|(?:from {word_comb} (import {modules_or}))\"  \n",
    "# )\n",
    "\n",
    "# this pattern will not match the proceeding and then in \n",
    "# group 1 will match the \n",
    "easy_import_pattern = (f\"(?:from {word_comb} )?\"\n",
    "f\"(import {modules_or} as {word_comb}|import {modules_or})\")\n",
    "\n",
    "easy_replacement = fr\"from {package_name} \\1\"\n",
    "\n",
    "if verbose:\n",
    "    print(f\"-- easy initial replacement --\")\n",
    "filu.file_regex_replace(\n",
    "    pattern = easy_import_pattern,\n",
    "    replacement = easy_replacement,\n",
    "    filepath = output_path,\n",
    "    overwrite_file = True,\n",
    "    verbose = verbose\n",
    ")\n",
    "\n",
    "if verbose:\n",
    "    print(f\"-- harder initial replacement --\")\n",
    "\n",
    "harder_import_pattern = f\"(?:from [.]+({modules_or} import {word_comb}))\"\n",
    "harder_replacement = fr\"from {package_name}.\\1\"\n",
    "filu.file_regex_replace(\n",
    "    pattern = harder_import_pattern,\n",
    "    replacement = harder_replacement,\n",
    "    filepath = output_path,\n",
    "    overwrite_file = True,\n",
    "    verbose = verbose\n",
    ")\n",
    "\n",
    "if verbose:\n",
    "    print(f\"-- easier relative replacement --\")\n",
    "\n",
    "easy_import_relative = f\"({ru.start_of_line_pattern})from {package_name} \"\n",
    "easy_replacement_relative = fr\"\\1from . \"\n",
    "\n",
    "filu.file_regex_replace(\n",
    "    pattern = easy_import_relative,\n",
    "    replacement = easy_replacement_relative,\n",
    "    filepath = output_path,\n",
    "    overwrite_file = True,\n",
    "    verbose = verbose\n",
    ")\n",
    "\n",
    "if verbose:\n",
    "    print(f\"-- harder relative replacement --\")\n",
    "    \n",
    "harder_import_relative = f\"({ru.start_of_line_pattern})from {package_name}.\"\n",
    "harder_replacement_relative = fr\"\\1from .\"\n",
    "\n",
    "filu.file_regex_replace(\n",
    "    pattern = harder_import_relative,\n",
    "    replacement = harder_replacement_relative,\n",
    "    filepath = output_path,\n",
    "    overwrite_file = True,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all docstrings (and replace with empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of multi-line strings = 1\n"
     ]
    }
   ],
   "source": [
    "from python_tools import string_utils as stru\n",
    "\n",
    "\n",
    "above_first_func_def = True\n",
    "\n",
    "data = filu.read_file(output_path)\n",
    "multi_line_comm = modu.multiline_str(\n",
    "    filepath = output_path,\n",
    "    verbose = verbose,\n",
    "    return_text=False,\n",
    "    above_first_func_def = above_first_func_def,\n",
    ")\n",
    "\n",
    "range_list = [k.span() for k in multi_line_comm]\n",
    "\n",
    "data_doc = stru.remove_range_list(\n",
    "    data,\n",
    "    range_list=range_list,\n",
    "    verbose = False,\n",
    ")\n",
    "\n",
    "all_doc = [modu.multiline_str_text(obj) for obj in multi_line_comm]\n",
    "\n",
    "\n",
    "    \n",
    "#data_doc = f\"{all_doc}\\n{data_doc}\"\n",
    "#filu.write_file(output_path,data=data_doc,replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorganizing the modules in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: To retrieve all of the modules, \\nand move the unique list to the top and bottom \\nof module\\n\\nPseudocode: \\n1) get a unique list of all the modules\\n2) remove all instances of those modules that occur at beginnings of the line\\n3) sort the modules into relative and non-relative\\n4) Remove the own file from the list\\n5) Create a prefix \\n'"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: To retrieve all of the modules, \n",
    "and move the unique list to the top and bottom \n",
    "of module\n",
    "\n",
    "Pseudocode: \n",
    "1) get a unique list of all the modules\n",
    "2) remove all instances of those modules that occur at beginnings of the line\n",
    "3) sort the modules into relative and non-relative\n",
    "4) Remove the own file from the list\n",
    "5) Create a prefix \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of matches (unique = True) = 21\n",
      "# of modules replaced = 21\n",
      "from copy import deepcopy\n",
      "from networkx.classes.function import path_weight as pw\n",
      "from networkx.drawing.nx_pydot import graphviz_layout\n",
      "import copy\n",
      "import itertools\n",
      "import matplotlib.pyplot as plt\n",
      "import networkx as nx\n",
      "import networkx.classes.function as cls_func\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pydot\n",
      "import random\n",
      "import time\n",
      "\n",
      "\n",
      "--- from python_tools ---\n",
      "from . import general_utils as gu\n",
      "from . import numpy_utils as nu\n",
      "from . import pandas_utils as pu\n",
      "from . import regex_utils as ru\n",
      "from . import string_utils as stru\n",
      "from . import tqdm_utils as tqu\n",
      "from .tqdm_utils import tqdm\n",
      "\n",
      "\n",
      "from . import networkx_utils as xu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "finds = modu.find_import_modules_in_file(\n",
    "    data = data_doc,\n",
    "    unique = True,\n",
    "    verbose = verbose,\n",
    "    beginning_of_line = True,\n",
    "    \n",
    ")\n",
    "\n",
    "finds = list(np.sort(finds))\n",
    "\n",
    "module_pattern = fr\"{ru.start_of_line_pattern}({'|'.join(finds)})\"\n",
    "data_doc_no_mod, count = re.subn(\n",
    "    pattern = module_pattern,\n",
    "    repl=\"\",\n",
    "    string=data_doc,\n",
    ")\n",
    "\n",
    "if verbose:\n",
    "    print(f\"# of modules replaced = {count}\")\n",
    "    \n",
    "pkg_list = list(pkg_to_module.keys())\n",
    "\n",
    "non_pkg_mods = []\n",
    "pkg_mods = dict()\n",
    "own_mod = []\n",
    "\n",
    "for k in finds:\n",
    "    if curr_mod in k:\n",
    "        own_mod.append(k)\n",
    "        continue\n",
    "    if \"from .\" in k:\n",
    "        if package_name not in pkg_mods:\n",
    "            pkg_mods[package_name] = []\n",
    "        pkg_mods[package_name].append(k)\n",
    "        continue\n",
    "        \n",
    "    for pkg in pkg_list:\n",
    "        if pkg in k:\n",
    "            if pkg not in pkg_mods:\n",
    "                pkg_mods[pkg] = []\n",
    "            pkg_mods[pkg].append(k)\n",
    "            continue\n",
    "    non_pkg_mods.append(k)\n",
    "    \n",
    "\n",
    "non_pkg_mods_str = \"\\n\".join(non_pkg_mods)\n",
    "own_mod_str = \"\\n\".join(own_mod)\n",
    "pkg_mods_str = \"\\n\\n\".join([f\"--- from {pkg} ---\\n\" + \"\\n\".join(m)\n",
    "                           for pkg,m in pkg_mods.items() ])\n",
    "\n",
    "if verbose:\n",
    "    print(non_pkg_mods_str)\n",
    "    print(f\"\\n\")\n",
    "    print(pkg_mods_str)\n",
    "    print(f\"\\n\")\n",
    "    print(own_mod_str)\n",
    "    \n",
    "separator = f\"\\n\\n\"\n",
    "\n",
    "if len(all_doc) > 0:\n",
    "    all_doc_str = \"\\n\\n\".join(all_doc)\n",
    "    all_doc_str = f\"'''{all_doc_str}\\n'''{separator}\"\n",
    "else:\n",
    "    all_doc_str = \"\"\n",
    "    \n",
    "if len(non_pkg_mods_str) > 0:\n",
    "    non_pkg_mods_str += separator\n",
    "if len(pkg_mods_str) > 0:\n",
    "    pkg_mods_str += separator\n",
    "    \n",
    "final_data = (\n",
    "    all_doc_str +\n",
    "    non_pkg_mods_str + \n",
    "    data_doc_no_mod +\n",
    "    pkg_mods_str + \n",
    "    own_mod_str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a new file\n",
    "filu.write_file(\n",
    "    output_path,\n",
    "    final_data,\n",
    "    replace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Get all of the modules used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of matches (unique = True) = 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['from .tqdm_utils import tqdm',\n",
       " 'import itertools',\n",
       " 'import pandas as pd',\n",
       " 'from . import general_utils as gu',\n",
       " 'import networkx.classes.function as cls_func',\n",
       " 'import numpy as np',\n",
       " 'from . import string_utils as stru',\n",
       " 'import pydot',\n",
       " 'from . import pandas_utils as pu',\n",
       " 'from . import regex_utils as ru',\n",
       " 'from copy import deepcopy',\n",
       " 'from networkx.classes.function import path_weight as pw',\n",
       " 'import networkx as nx',\n",
       " 'import time',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'import random',\n",
       " 'import copy',\n",
       " 'from networkx.drawing.nx_pydot import graphviz_layout',\n",
       " 'from . import networkx_utils as xu',\n",
       " 'from . import tqdm_utils as tqu',\n",
       " 'from . import numpy_utils as nu']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules_used = modu.find_import_modules_in_file(\n",
    "    filename=filepath,\n",
    "    pattern = pattern_import,\n",
    "    verbose = verbose,\n",
    "    unique = True\n",
    ")\n",
    "modules_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Divide modules into referenced outside of package and those not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_directory = [\n",
    "    \"/meshAfterParty/meshAfterParty/\",\n",
    "    \"/python_tools/python_tools/\",\n",
    "    \"/graph_tools/graph_tools/\",\n",
    "    \"/neuron_morphology_tools/neuron_morphology_tools/\",\n",
    "    \"/pytorch_tools/pytorch_tools/\",\n",
    "]\n",
    "\n",
    "\n",
    "#modu.prefix_module_imports_in_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of modules = 36\n",
      "import_str = (?:\\A|\\n)((?:import [a-zA-Z._]+ as [a-zA-Z._]+)|(?:from [a-zA-Z._]+ import [a-zA-Z._]+ as [a-zA-Z._]+)|(?:import [a-zA-Z._]+)|(?:from [a-zA-Z._]+ import [a-zA-Z._]+))\n",
      "# of matches (unique = False) = 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['from . import general_utils as gu',\n",
       " 'from . import numpy_utils as nu',\n",
       " 'from . import pandas_utils as pu',\n",
       " 'from . import regex_utils as ru',\n",
       " 'from . import string_utils as stru',\n",
       " 'from . import tqdm_utils as tqu',\n",
       " 'from .tqdm_utils import tqdm',\n",
       " 'from copy import deepcopy',\n",
       " 'from networkx.classes.function import path_weight as pw',\n",
       " 'from networkx.drawing.nx_pydot import graphviz_layout',\n",
       " 'import copy',\n",
       " 'import itertools',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'import networkx as nx',\n",
       " 'import networkx.classes.function as cls_func',\n",
       " 'import numpy as np',\n",
       " 'import pandas as pd',\n",
       " 'import pydot',\n",
       " 'import random',\n",
       " 'import time',\n",
       " 'from . import networkx_utils as xu']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = \"/python_tools/python_tools/\"\n",
    "\n",
    "modules = modu.modules_from_directory(\n",
    "    directory = directory,\n",
    "    verbose = verbose\n",
    ")\n",
    "\n",
    "pattern_import = modu.import_pattern_str(\n",
    "    #modules = modules,\n",
    "    verbose = verbose\n",
    ")\n",
    "py_tools_imports = modu.find_import_modules_in_file(\n",
    "    filename=filepath,\n",
    "    pattern = pattern_import,\n",
    "    verbose = verbose,\n",
    "    unique = False\n",
    ")\n",
    "py_tools_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Get all the member variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of global variables = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['downstream_name', 'node_id_default', 'upstream_name']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_tools import networkx_utils as xu\n",
    "iu.global_vars(xu,verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Can we detect member variables without the module? no not necessarily\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Get all docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of multi-line strings = 3\n"
     ]
    }
   ],
   "source": [
    "multi_line_comm = modu.multiline_str(\n",
    "    filepath = filepath,\n",
    "    verbose = verbose,\n",
    "    return_text = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
