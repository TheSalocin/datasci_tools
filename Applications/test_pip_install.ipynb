{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_tools import numpy_utils as nu\n",
    "from python_tools import pandas_utils as pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_tools import package_utils as pku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/python_tools/python_tools/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_tools import numpy_utils as nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find large multi-line comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?:\\\\%^|\\\\n)'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_tools import regex_utils as reu\n",
    "reu.start_of_line_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of multi-line strings = 3\n"
     ]
    }
   ],
   "source": [
    "from python_tools import module_utils as modu\n",
    "multi_line_comm = modu.multiline_str(\n",
    "    filepath = \"/python_tools/python_tools/networkx_utils.py\",\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect when something in a multi-line comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of multi-line strings = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<regex.Match object; span=(0, 34), match='\"\"\"\\nThis is the first comment\\n\\n\"\"\"'>,\n",
       " <regex.Match object; span=(48, 118), match='\\n\"\"\"\\nanother commont\\n\\'\\'\\'\\nmulti-line inside another multi-line\\n\\'\\'\\'\\n\\n\"\"\"'>,\n",
       " <regex.Match object; span=(119, 142), match=\"\\n'''\\nA last comment\\n'''\">]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re\n",
    "from python_tools import regex_utils as ru\n",
    "from python_tools import file_utils as filu\n",
    "\n",
    "def multiline_str(\n",
    "    filepath,\n",
    "    beginning_of_line = True,\n",
    "    verbose = False,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Purpose: find multiline strings in a module\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = ru.multiline_str_pattern\n",
    "    if beginning_of_line:\n",
    "        pattern = reu.start_of_line_pattern + pattern\n",
    "\n",
    "    pattern = re.compile(\n",
    "        pattern,\n",
    "        flags=re.DOTALL\n",
    "    )\n",
    "\n",
    "    data = filu.read_file(filepath)\n",
    "\n",
    "    total_results = list(pattern.finditer(data))\n",
    "    if verbose:\n",
    "        print(f\"# of multi-line strings = {len(total_results)}\")\n",
    "    return total_results\n",
    "\n",
    "multiline_str(\n",
    "    filepath = \"/python_tools/python_tools/example_re.py\",\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all global variables of module that aren't functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of global variables = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['non_variable_detectors']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_tools import numpy_utils as nu\n",
    "from python_tools import inspect_utils as iu\n",
    "iu.global_vars(nu,verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G_from_adjacency_matrix',\n",
       " 'G_from_edges',\n",
       " 'G_from_pandas_edgelist',\n",
       " 'add_new_coordinate_node',\n",
       " 'add_node_attributes_to_edge_df',\n",
       " 'adjacency_feature_info',\n",
       " 'adjacency_matrix',\n",
       " 'aggregate_values_on_relative_nodes',\n",
       " 'all_children_nodes',\n",
       " 'all_connected_subgraphs',\n",
       " 'all_downstream_nodes',\n",
       " 'all_downstream_nodes_from_nodes',\n",
       " 'all_downstream_nodes_including_node',\n",
       " 'all_downstream_nodes_including_self',\n",
       " 'all_edges_on_shortest_paths_between_nodes',\n",
       " 'all_nodes_on_shortest_paths_between_nodes',\n",
       " 'all_pairs_shortest_path_length_matrix',\n",
       " 'all_pairs_shortest_path_matrix',\n",
       " 'all_parent_nodes',\n",
       " 'all_path_from_start_to_end_nodes',\n",
       " 'all_paths_to_leaf_nodes',\n",
       " 'all_subgraph_edges',\n",
       " 'all_subgraphs',\n",
       " 'all_upstream_nodes',\n",
       " 'all_upstream_nodes_from_nodes',\n",
       " 'all_upstream_nodes_including_node',\n",
       " 'apply_edge_attribute_dict_to_graph',\n",
       " 'balanced_tree',\n",
       " 'binary_tree',\n",
       " 'binary_tree_from_di_tree',\n",
       " 'check_downstream_nodes_on_same_path',\n",
       " 'circle_graph',\n",
       " 'closest_k_leaf_neighbors_in_binary_tree',\n",
       " 'combine_edge_attributes',\n",
       " 'combine_graphs',\n",
       " 'common_children_nodes',\n",
       " 'common_parent_nodes',\n",
       " 'common_relational_nodes',\n",
       " 'compare_endpoints',\n",
       " 'compare_networks',\n",
       " 'complete_graph',\n",
       " 'complete_graph_from_node_ids',\n",
       " 'compute_edge_statistic',\n",
       " 'compute_node_attribute',\n",
       " 'configuration_model',\n",
       " 'connected_component_with_node',\n",
       " 'connected_components',\n",
       " 'connected_components_from_nodes_edges',\n",
       " 'connected_components_subgraphs',\n",
       " 'convert_to_non_multi',\n",
       " 'copy_G_without_data',\n",
       " 'create_and_delete_edges',\n",
       " 'cycle_graph',\n",
       " 'deepcopy',\n",
       " 'degree_1_max_edge_min_max_weight_graph',\n",
       " 'degree_distribution',\n",
       " 'degree_matrix_from_adj',\n",
       " 'degree_sequence',\n",
       " 'degree_sequence_from_adj',\n",
       " 'delete_node_attributes',\n",
       " 'derived_edge_attribute',\n",
       " 'derived_edge_attribute_from_func',\n",
       " 'derived_node_attribute',\n",
       " 'derived_node_attribute_from_func',\n",
       " 'directed_configuration_model',\n",
       " 'downstream_conn_comps',\n",
       " 'downstream_edges',\n",
       " 'downstream_edges_neighbors',\n",
       " 'downstream_edges_neighbors_not_exact',\n",
       " 'downstream_nodes',\n",
       " 'draw_tree',\n",
       " 'edge_and_node_df',\n",
       " 'edge_attribute_dict_from_edges',\n",
       " 'edge_attribute_dict_from_node',\n",
       " 'edge_df',\n",
       " 'edge_df_from_G',\n",
       " 'edge_df_multi',\n",
       " 'edge_df_optimized',\n",
       " 'edge_graph',\n",
       " 'edge_list_from_graph_type',\n",
       " 'edge_str_from_G',\n",
       " 'edge_subgraph',\n",
       " 'edge_to_index',\n",
       " 'edgelist_from_adjacency_matrix',\n",
       " 'edges',\n",
       " 'edges_and_weights_to_graph',\n",
       " 'empty_graph_type_from_G',\n",
       " 'end_nodes',\n",
       " 'end_nodes_of_digraph',\n",
       " 'endpoint_connectivity',\n",
       " 'expand_edges_to_nodes_within_radius',\n",
       " 'expand_nodes_to_all_nodes_on_path_between_nodes',\n",
       " 'feature_matrix_from_G',\n",
       " 'filter_away_downstream_nodes',\n",
       " 'filter_down_edge_attributes',\n",
       " 'filter_down_node_attributes',\n",
       " 'find_all_cycles',\n",
       " 'find_nodes_within_certain_distance_of_target_node',\n",
       " 'find_reciprocal_connections',\n",
       " 'find_skeletal_distance_along_graph_node_path',\n",
       " 'from_pandas_edgelist',\n",
       " 'get_all_attributes_for_edges',\n",
       " 'get_all_attributes_for_nodes',\n",
       " 'get_all_nodes_with_certain_attribute_key',\n",
       " 'get_coordinate_by_graph_node',\n",
       " 'get_coordinate_degree',\n",
       " 'get_edge_attribute',\n",
       " 'get_edge_attributes',\n",
       " 'get_edge_attributes_df',\n",
       " 'get_edge_weight',\n",
       " 'get_edges_with_attributes_dict',\n",
       " 'get_edges_with_weights',\n",
       " 'get_graph_attr',\n",
       " 'get_graph_node_by_coordinate',\n",
       " 'get_graph_node_by_coordinate_old',\n",
       " 'get_graph_nodes_by_coordinates',\n",
       " 'get_neighbor_min_weighted_edge',\n",
       " 'get_neighbors',\n",
       " 'get_neighbors_simple',\n",
       " 'get_node_attribute_dict',\n",
       " 'get_node_attribute_for_all_nodes',\n",
       " 'get_node_attributes',\n",
       " 'get_node_degree',\n",
       " 'get_node_degree_in',\n",
       " 'get_node_degree_out',\n",
       " 'get_node_list',\n",
       " 'get_nodes_greater_or_equal_degree_k',\n",
       " 'get_nodes_greater_or_equal_in_degree_k',\n",
       " 'get_nodes_greater_or_equal_out_degree_k',\n",
       " 'get_nodes_less_or_equal_degree_k',\n",
       " 'get_nodes_less_or_equal_in_degree_k',\n",
       " 'get_nodes_less_or_equal_out_degree_k',\n",
       " 'get_nodes_of_degree_k',\n",
       " 'get_nodes_of_in_degree_k',\n",
       " 'get_nodes_of_out_degree_k',\n",
       " 'get_nodes_with_attribute_value',\n",
       " 'get_nodes_with_attributes_dict',\n",
       " 'get_nx_type',\n",
       " 'get_starting_node',\n",
       " 'graph_attr_dict',\n",
       " 'graph_from_non_unique_vertices_edges',\n",
       " 'graph_from_unique_vertices_edges',\n",
       " 'graph_to_edges_and_weights',\n",
       " 'graph_to_lowest_weighted_sum_singular_matches',\n",
       " 'graph_type_from_G',\n",
       " 'graphviz_layout',\n",
       " 'group_nodes_into_siblings',\n",
       " 'hierarchy_pos',\n",
       " 'high_degree_nodes',\n",
       " 'in_degree_sequence',\n",
       " 'in_degree_sequence_from_adj',\n",
       " 'index_to_edge',\n",
       " 'is_digraph',\n",
       " 'is_frozen',\n",
       " 'is_graph',\n",
       " 'is_graph_any',\n",
       " 'is_isomorphic',\n",
       " 'is_multigraph',\n",
       " 'is_tree',\n",
       " 'laplacian',\n",
       " 'laplacian_from_adj',\n",
       " 'laplacian_matrix',\n",
       " 'largest_component_n_nodes',\n",
       " 'largest_component_node_perc',\n",
       " 'largest_component_subgraph',\n",
       " 'largest_connected_component',\n",
       " 'leaf_nodes',\n",
       " 'least_downstream_node',\n",
       " 'line_graph',\n",
       " 'local_radius_conn_comps',\n",
       " 'lowest_weighted_sum_singular_matches',\n",
       " 'max_node_degree',\n",
       " 'min_cut_to_partition_node_groups',\n",
       " 'modularity',\n",
       " 'modularity_matrix',\n",
       " 'most_upstream_node',\n",
       " 'motif_Gs_for_n_nodes',\n",
       " 'motif_strs_for_n_nodes',\n",
       " 'move_node_from_exclusion_list',\n",
       " 'n_all_downstream_nodes',\n",
       " 'n_all_upstream_nodes',\n",
       " 'n_common_parent_nodes',\n",
       " 'n_connected_components',\n",
       " 'n_downstream_nodes',\n",
       " 'n_edges',\n",
       " 'n_edges_in',\n",
       " 'n_edges_out',\n",
       " 'n_nodes',\n",
       " 'n_sibling_nodes',\n",
       " 'neighbors',\n",
       " 'node_df',\n",
       " 'node_df_features',\n",
       " 'node_df_from_node_query',\n",
       " 'node_query',\n",
       " 'node_to_edges',\n",
       " 'nodes',\n",
       " 'nodes_DFS',\n",
       " 'nodes_edges_only_G',\n",
       " 'nodes_from_node_query',\n",
       " 'nodes_in_kept_group',\n",
       " 'nodes_in_kept_groups_after_deletion',\n",
       " 'nodes_on_all_pairwise_paths_betweeen_nodes',\n",
       " 'nodes_with_no_edges',\n",
       " 'nodes_with_non_none_attributes',\n",
       " 'nodes_with_parent_branching',\n",
       " 'nodes_with_parent_non_branching',\n",
       " 'nodes_within_radius',\n",
       " 'non_leaf_nodes',\n",
       " 'out_degree_sequence',\n",
       " 'out_degree_sequence_from_adj',\n",
       " 'parent_node',\n",
       " 'path_distance',\n",
       " 'path_graph',\n",
       " 'path_length_from_path',\n",
       " 'path_weight',\n",
       " 'pickle_graph',\n",
       " 'print_node_edges_counts',\n",
       " 'pw',\n",
       " 'query_bidirectional',\n",
       " 'query_to_subgraph',\n",
       " 'radius_threshold_graph_from_coordinates',\n",
       " 'random_edges_from_existing_edges',\n",
       " 'random_edges_from_existing_nodes',\n",
       " 'random_edges_subgraph',\n",
       " 'relabel_node_names',\n",
       " 'remove_cycle',\n",
       " 'remove_edge_reattach_children_di',\n",
       " 'remove_inter_partition_edges',\n",
       " 'remove_node_reattach_children_di',\n",
       " 'remove_nodes_from',\n",
       " 'remove_nodes_with_no_edges',\n",
       " 'remove_self_loops',\n",
       " 'remove_selfloops',\n",
       " 'rename_nodes',\n",
       " 'reverse_DiGraph',\n",
       " 'reverse_DiGraph_old',\n",
       " 'self_loop_edges',\n",
       " 'set_edge_attribute',\n",
       " 'set_edge_attribute_defualt',\n",
       " 'set_edge_attribute_from_node_attribute',\n",
       " 'set_graph_attr',\n",
       " 'set_graph_attr_with_dict',\n",
       " 'set_node_attribute',\n",
       " 'set_node_attribute_default',\n",
       " 'set_node_attributes_dict',\n",
       " 'set_node_attributes_from_df',\n",
       " 'set_node_data',\n",
       " 'shortest_path',\n",
       " 'shortest_path_along_node_subset',\n",
       " 'shortest_path_along_node_subset_old',\n",
       " 'shortest_path_between_two_sets_of_nodes',\n",
       " 'shortest_path_from_most_upstream',\n",
       " 'shortest_path_graph',\n",
       " 'shortest_path_graph_from_most_upstream',\n",
       " 'shortest_path_length',\n",
       " 'sibling_nodes',\n",
       " 'star_graph',\n",
       " 'starting_node_from_DiG',\n",
       " 'subgraph_downstream_of_node',\n",
       " 'subgraph_from_edge_query',\n",
       " 'subgraph_from_edges',\n",
       " 'subgraph_from_node_query',\n",
       " 'subgraph_within_radius',\n",
       " 'sum_downstream_attribute',\n",
       " 'sum_of_edge_weights',\n",
       " 'undirected_sym_G_from_DiG',\n",
       " 'unique_vertices_edges_from_vertices_edges',\n",
       " 'unpickle_graph',\n",
       " 'upstream_edges',\n",
       " 'upstream_edges_neighbors',\n",
       " 'upstream_edges_neighbors_slow',\n",
       " 'upstream_node',\n",
       " 'values_on_relative_nodes']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_tools import networkx_utils as xu\n",
    "results = inspect.getmembers(xu,inspect.isfunction)\n",
    "results_names = [k[0] for k in results]\n",
    "results_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose: Do a mass replacement of the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/python_tools/python_tools/filtering_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/json_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/matplotlib_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/statistics_visualizations.py'),\n",
       " PosixPath('/python_tools/python_tools/requirement_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/networkx_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/pretty_print_confusion_matrix.py'),\n",
       " PosixPath('/python_tools/python_tools/numpy_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/ipyvolume_movie_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/dict_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/regex_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/hash_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/statistics_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/general_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/string_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/algorithms_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/ipyvolume_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/pandas_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/pathlib_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/system_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/package_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/scipy_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/seaborn_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/matlab_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/argparse_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/function_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/file_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/data_struct_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/linalg_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/widget_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/dj_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/tqdm_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/mesh_utils.py'),\n",
       " PosixPath('/python_tools/python_tools/__init__.py')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from python_tools import pathlib_utils as pu\n",
    "p = Path(\"/python_tools/python_tools/\")\n",
    "files = pu.py_files(p,return_stem = False)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: Want to replace \n",
    "\"\"\"\n",
    "\n",
    "import package_utils as pku\n",
    "\n",
    "pku.prefix_module_imports_in_files(\n",
    "    filepaths = files,#\"/python_tools/python_tools/numpy_utils.py\",\n",
    "    modules_directory = \"../python_tools\",\n",
    "    modules = None,\n",
    "    prefix = \"from python_tools \",\n",
    "    overwrite_file = True,\n",
    "    output_filepath = None,# \"text_revised.txt\",\n",
    "    verbose = True,\n",
    "    ignore_files = [\"__init__\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_levels above = 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: find the relative path between a file\n",
    "and parent directory\n",
    "\n",
    "Pseudocode: \n",
    "1) Get the relative path\n",
    "2) replace any \"//\" with just \"/\"\n",
    "3) count the number of backslashes --> that number of levels up\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "verbose = True\n",
    "path = Path(\"/python_tools/python_tools/dj_utils.py\")\n",
    "secondparent = \"/python_tools/\"\n",
    "relative_path = str(path.relative_to(secondparent)).replace(\"//\",\"/\")\n",
    "n_levels = len(re.findall(re.compile(\"/\"),relative_path))\n",
    "if verbose:\n",
    "    print(f\"n_levels above = {n_levels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_levels above = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plu.n_levels_parent_above(\n",
    "    filepath = Path(\"/python_tools/python_tools/dj_utils.py\"),\n",
    "    parent = \"/python_tools/\",\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from ... '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_tools import package_utils as pku\n",
    "filepath = Path(\"/python_tools/python_tools/dj_utils.py\")\n",
    "parent = \"/\"\n",
    "pku.relative_import_from(parent,filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add prefixes to file from it's own package and other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/meshAfterParty/meshAfterParty/',\n",
       " '/python_tools/python_tools/',\n",
       " '/graph_tools/graph_tools/',\n",
       " '/neuron_morphology_tools/neuron_morphology_tools/',\n",
       " '/pytorch_tools/pytorch_tools/']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules_directory = [\n",
    "    \"/meshAfterParty/meshAfterParty/\",\n",
    "    \"/python_tools/python_tools/\",\n",
    "    \"/graph_tools/graph_tools/\",\n",
    "    \"/neuron_morphology_tools/neuron_morphology_tools/\",\n",
    "    \"/pytorch_tools/pytorch_tools/\",\n",
    "]\n",
    "\n",
    "modules_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Working on file: /meshAfterParty/meshAfterParty/spine_utils.py\n",
      "--Getting files from /meshAfterParty/meshAfterParty/\n",
      "# of py files = 88\n",
      "# of substitutions = 31\n",
      "  --> output_filepath = /meshAfterParty/meshAfterParty/spine_utils_replaced.py\n",
      "--Getting files from /python_tools/python_tools/\n",
      "# of py files = 34\n",
      "# of substitutions = 22\n",
      "  --> output_filepath = /meshAfterParty/meshAfterParty/spine_utils_replaced.py\n",
      "--Getting files from /graph_tools/graph_tools/\n",
      "# of py files = 7\n",
      "# of substitutions = 0\n",
      "  --> output_filepath = /meshAfterParty/meshAfterParty/spine_utils_replaced.py\n",
      "--Getting files from /neuron_morphology_tools/neuron_morphology_tools/\n",
      "# of py files = 6\n",
      "# of substitutions = 0\n",
      "  --> output_filepath = /meshAfterParty/meshAfterParty/spine_utils_replaced.py\n",
      "--Getting files from /pytorch_tools/pytorch_tools/\n",
      "# of py files = 19\n",
      "# of substitutions = 0\n",
      "  --> output_filepath = /meshAfterParty/meshAfterParty/spine_utils_replaced.py\n"
     ]
    }
   ],
   "source": [
    "from python_tools import package_utils as pku\n",
    "pku.prefix_module_imports_in_files(\n",
    "    filepaths=[\"/meshAfterParty/meshAfterParty/spine_utils.py\"],\n",
    "    modules_directory = modules_directory,\n",
    "    overwrite_file=False,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better way of cleaning up modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Idea for how to do imports: \n",
    "\n",
    "all non-relative imports\n",
    "all global variables\n",
    "all relative imports\n",
    "functions\n",
    "self as a function\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do A Cleaning up of the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from python_tools import pathlib_utils as pu\n",
    "p = Path(\"/python_tools/python_tools/\")\n",
    "files = pu.py_files(p,return_stem = False)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filu.clean_module_imports(\n",
    "    filename  = \"/python_tools/python_tools/networkx_utils.py\",\n",
    "    overwrite_file = False,\n",
    "    verbose = True,\n",
    "    relative_package = \"python_tools\",\n",
    "    relative_replacement = \".\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_tools import file_utils as filu\n",
    "for f in files:\n",
    "    filu.clean_module_imports(\n",
    "        filename  = f,\n",
    "        overwrite_file = True,\n",
    "        verbose = True,\n",
    "        relative_package = \"python_tools\",\n",
    "        relative_replacement = \".\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filu.search_directory_files_for_str(\"../python_tools/\",search_str=\"tqdm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"pattern = (?<!from python_tools )(import (filtering_utils|pandas_utils_replaced|json_utils|matplotlib_utils|statistics_visualizations|requirement_utils|networkx_utils|pretty_print_confusion_matrix|numpy_utils|ipyvolume_movie_utils|dict_utils|regex_utils|hash_utils|statistics_utils|general_utils|string_utils|algorithms_utils|ipyvolume_utils|pandas_utils|pathlib_utils|system_utils|package_utils|scipy_utils|seaborn_utils|matlab_utils|argparse_utils|function_utils|file_utils|data_struct_utils|linalg_utils|widget_utils|dj_utils|tqdm_utils|mesh_utils))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Mass Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_tools import file_utils as filu\n",
    "for f in files:\n",
    "    filu.file_regex_replace(\n",
    "        filepath=f,\n",
    "        pattern = \"from tqdm_utils import tqdm\",\n",
    "        replacement = \"from python_tools.tqdm_utils import tqdm\",\n",
    "        overwrite_file = True,\n",
    "        verbose = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filu.clean_module_imports(\n",
    "    filename  = f\"/python_tools/python_tools/numpy_utils.py\",\n",
    "    overwrite_file = False,\n",
    "    verbose = False,\n",
    "    relative_package = \"python_tools\",\n",
    "    relative_replacement = \".\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.findall(re.compile(filu.import_pattern_str()),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filu.file_regex_replace(\n",
    "    filepath=filename,\n",
    "    pattern = filu.import_pattern_str(beginning_of_line = True),\n",
    "    replacement = \"\\n#\" + r\"\\1\",\n",
    "    overwrite_file = False,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_tools import package_utils as pku\n",
    "pku.module_names_from_directories(\"/python_tools/python_tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "string = \"\\nHello there \\nYolo is this_anything \\n_importpackage_name\"\n",
    "print(string)\n",
    "pattern = re.compile(\"\\n(?:[a-zA-Z]+)\")\n",
    "finds = list(re.finditer(pattern,string))\n",
    "finds[0].groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_tools import file_utils as filu\n",
    "\n",
    "finds = filu.find_import_modules_in_file(\n",
    "    filename  = f\"/python_tools/python_tools/numpy_utils.py\",\n",
    "    unique = True,\n",
    "    verbose = True,\n",
    "    beginning_of_line = True,\n",
    ")\n",
    "\n",
    "finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.string[f.start():f.end()][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports\n",
    "for f in finds:\n",
    "    print(f.string[f.start():f.end()][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filu.file_regex_replace(\n",
    "        filepath=\"/python_tools/python_tools/pandas_utils.py\",\n",
    "        pattern = \"from python_tools \",\n",
    "        replacement = \"import \",\n",
    "        overwrite_file = False,\n",
    "        verbose = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_tools import file_utils as filu\n",
    "for f in files:\n",
    "    filu.file_regex_replace(\n",
    "        filepath=f,\n",
    "        pattern = \"from tqdm_utils import tqdm\",\n",
    "        replacement = \"from python_tools.tqdm_utils import tqdm\",\n",
    "        overwrite_file = True,\n",
    "        verbose = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex_utils as ru\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_find[0].groups()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"hello there make sure to match\"\n",
    "pattern = r\"(?<!there)(make (sure))\"\n",
    "pattern = re.compile(pattern)\n",
    "s_find = list(pattern.finditer(string))\n",
    "s_find[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Have an option of what to place in front of it:\n",
    "- \"from . \"\n",
    "- \"from package_name \"\n",
    "- have a dictionary that maps the current files to \n",
    "the right prefix\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "p = Path(\"./test.txt\")\n",
    "p.stem,p.suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def file_regex_replace(\n",
    "    pattern,\n",
    "    replacement,\n",
    "    filepath,\n",
    "    overwrite_file = False,\n",
    "    output_filepath = None,# \"text_revised.txt\",\n",
    "    default_suffix = \"_replaced\",\n",
    "    verbose = False,\n",
    "    regex = True,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Purpose: To replace certain text \n",
    "    in a file and either write changes\n",
    "    back to same file or to a new one\n",
    "\n",
    "    Pseudocode:\n",
    "    1) open the file\n",
    "    2) read in the contents of the file\n",
    "    3) using the regex replace function (with potential to use captured groups)\n",
    "    \"\"\"\n",
    "    if overwrite_file:\n",
    "        output_filepath = filepath\n",
    "    \n",
    "    if output_filepath is None:\n",
    "        p = Path(filepath)\n",
    "        output_filepath = f\"{p.stem}{default_suffix}{p.suffix}\"\n",
    "\n",
    "\n",
    "    # Opening our text file in read only\n",
    "    # mode using the open() function\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "        # Searching and replacing the text\n",
    "        # using the replace() function\n",
    "        if regex:\n",
    "            data,count = re.subn(pattern, replacement, data)\n",
    "            if verbose:\n",
    "                print(f\"# of substitutions = {count}\")\n",
    "        else:\n",
    "            data = data.replace(pattern,replacement)\n",
    "\n",
    "    # Opening our text file in write only\n",
    "    # mode to write the replaced content\n",
    "    with open(output_filepath, 'w') as file:\n",
    "\n",
    "        # Writing the replaced data in our\n",
    "        # text file\n",
    "        file.write(data)\n",
    "        \n",
    "    #return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_regex_replace(\n",
    "    pattern = r\"(hello|this)\",\n",
    "    replacement = r\"new \\1\",\n",
    "    filepath = \"test.txt\",\n",
    "    verbose = True,\n",
    "    overwrite_file = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/python_tools/python_tools/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy_utils_replaced as nur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import file_utils as filu\n",
    "def file_regex_add_prefix(\n",
    "    pattern,\n",
    "    prefix,\n",
    "    filepath,\n",
    "    overwrite_file = False,\n",
    "    output_filepath = None,# \"text_revised.txt\",\n",
    "    default_suffix = \"_replaced\",\n",
    "    verbose = False,\n",
    "    regex = True,\n",
    "    **kwargs,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Purpose: Add a prefix in front of certain patterns in file\n",
    "    \"\"\"\n",
    "\n",
    "    return filu.file_regex_replace(\n",
    "        pattern = pattern,\n",
    "        replacement = fr\"{prefix}\" + r\"\\1\",\n",
    "        filepath=filepath,\n",
    "        overwrite_file = overwrite_file,\n",
    "        output_filepath = output_filepath,# \"text_revised.txt\",\n",
    "        default_suffix = default_suffix,\n",
    "        verbose = verbose,\n",
    "        regex = regex,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filu.file_regex_add_prefix(\n",
    "    pattern = \"(new hello)\",\n",
    "    prefix = \"from . \",\n",
    "    filepath = \"test.txt\",\n",
    "    overwrite_file=True,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib_utils as plu\n",
    "# import numpy_utils as nu\n",
    "# import file_utils as filu\n",
    "# import io\n",
    "\n",
    "\n",
    "# def prefix_module_imports_in_files(\n",
    "#     filepaths,\n",
    "#     modules_directory = \"../python_tools\",\n",
    "#     modules = None,\n",
    "#     prefix = \"from . \",\n",
    "#     overwrite_file = False,\n",
    "#     output_filepath = None,# \"text_revised.txt\",\n",
    "#     verbose = False,\n",
    "#     ignore_files = [\"__init__\"],\n",
    "#     ):\n",
    "# \"\"\"\n",
    "# want to add a prefixes before\n",
    "# modules that are imported in a file\n",
    "\n",
    "# Pseudocode: \n",
    "# 1) if given a directory: get a list of the module names\n",
    "# 2) Construct a regex pattern ORing the potential list\n",
    "# 3) add the prefix before\n",
    "# 4) write to a new file or old file\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# #1) if given a directory: get a list of the module names\n",
    "# if modules is None:\n",
    "    \n",
    "#     modules_directory = nu.to_list(modules_directory)\n",
    "#     modules = []\n",
    "    \n",
    "#     for directory in modules_directory:\n",
    "        \n",
    "#         if verbose:\n",
    "#             print(f\"--Getting files from {directory}\")\n",
    "            \n",
    "#         modules += plu.files_of_ext_type(\n",
    "#             directory = directory,\n",
    "#             ext = \"py\",\n",
    "#             verbose = verbose\n",
    "#         )\n",
    "# else:\n",
    "#     modules = [Path(k) for k in nu.to_list(modules)]\n",
    "\n",
    "# modules = [k.stem for k in modules if k.stem not in ignore_files]\n",
    "\n",
    "# #2) Construct a regex pattern ORing the potential list\n",
    "# pattern = f\"(import ({'|'.join(modules)}))\"\n",
    "# #replacement = fr\"{prefix} import \\1\"\n",
    "\n",
    "# filepaths = nu.to_list(filepaths)\n",
    "\n",
    "# #4) write to a new file or old file\n",
    "# for f in filepaths:\n",
    "#     if verbose:\n",
    "#         print(f\"--- Working on file: {f}\")\n",
    "#     filu.file_regex_add_prefix(\n",
    "#         pattern=pattern,\n",
    "#         prefix=prefix,\n",
    "#         filepath=f,\n",
    "#         overwrite_file = overwrite_file,\n",
    "#         output_filepath = output_filepath,# \"text_revised.txt\",\n",
    "#         verbose = verbose,\n",
    "#         regex = True,\n",
    "#     )\n",
    "    \n",
    "import package_utils as pku\n",
    "\n",
    "pku.prefix_module_imports_in_files(\n",
    "    filepaths = \"../python_tools/numpy_utils.py\",\n",
    "    modules_directory = \"../python_tools\",\n",
    "    modules = None,\n",
    "    prefix = \"from . \",\n",
    "    overwrite_file = False,\n",
    "    output_filepath = None,# \"text_revised.txt\",\n",
    "    verbose = True,\n",
    "    ignore_files = [\"__init__\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
